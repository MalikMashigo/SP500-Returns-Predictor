# S&P 500 Price Movement Prediction Using Neural Networks
# Malik Mashigo

## Part 1: High-Level Solution Description

### Problem Formulation
For my semester project, I'm building a neural network to predict short-term price movements in the S&P 500 index. Instead of trying to predict exact prices (which seems basically impossible given market noise), I'm framing this as a classification problem where the model predicts whether the index will go up, down, or stay relatively flat over some future window like the next day or next few days. This makes way more sense from a practical standpoint because traders don't need to know the exact price, they just need to know which direction to bet on. Plus, classification gives me cleaner metrics to work with compared to trying to measure regression error on noisy financial data.

### Proposed Neural Architecture
The core architecture I'm planning is a multi-input neural network that processes different types of features simultaneously. The main component will be a Bidirectional LSTM that handles sequential price data, similar to how my BiLSTM POS tagger from NLP class used context from both directions to get over 95% accuracy. The LSTM will process sequences of historical OHLC data (open, high, low, close prices), trading volume, volatility measures, and various moving averages over different time windows. Alongside the LSTM, I'll have a separate input stream for technical indicators that traders actually use like RSI, MACD, and Bollinger Bands. These will go through their own dense layers before getting concatenated with the LSTM outputs. I'm basically stealing the idea from NLP where combining different feature types generally works better than single-stream models. I'll also include broader market context features like the VIX, treasury yields, and sector performance data to give the model a sense of overall market conditions.

### Training and Evaluation Strategy
For the final classification, I'll stack some dense layers with dropout for regularization, then use a softmax output for three classes representing down, flat, or up movements. The loss function will be categorical cross-entropy, and I'll use Adam optimizer since it's worked well for me in past projects. For evaluation, I'll look at accuracy but also F1-scores per class, confusion matrices to see what mistakes the model makes, and maybe even simulate a trading strategy to calculate risk-adjusted returns using something like the Sharpe ratio.

### Data Requirements and Preprocessing
My primary dataset will be S&P 500 historical data from something like Yahoo Finance or Alpha Vantage, going back ideally 10 to 20 years to capture different market cycles. The critical thing with financial data is that I can't just randomly shuffle it for train, validation, and test splits because that would leak future information into training. Instead, I'll do a temporal split with maybe 70% for training (roughly 2005 to 2019), 15% for validation (2019 to 2022), and 15% for testing (2022 to 2025). For secondary datasets, I'll need market indicators like VIX data from CBOE, treasury rates from FRED, and sector ETF data for major sectors like tech, financials, healthcare, energy, and consumer goods. The preprocessing pipeline will need to handle missing data from market holidays and weekends, normalize all the features, create rolling window sequences where I use like 30 days of history to predict the next day, generate labels by calculating forward returns and bucketing them into my three classes, and potentially balance the classes since markets historically trend up more than down.

### Expected Challenges
I'm expecting several challenges with this project. First, there's the whole market efficiency thing where if markets are truly efficient, there shouldn't be predictable patterns for a model to learn. Second, financial data is non-stationary, meaning its statistical properties change over time, so a model trained on the 2010s bull market might completely fail when tested on 2020s volatility. Third, overfitting is a massive risk when you have thousands of parameters but limited truly independent samples since consecutive trading days are highly correlated. Fourth, I'll need to deal with class imbalance since the market tends to go up over long periods. And finally, there are hundreds of possible technical indicators I could include, so I need to be smart about feature selection to avoid the curse of dimensionality.

### AI Tool Usage
I used Claude to brainstorm different approaches and talk through the architecture choices. We discussed whether regression or classification made more sense, explored different neural architectures, and worked through how to properly split time series data. The conversation also helped me identify which technical indicators and market features would be most relevant and think about evaluation metrics beyond just accuracy. The core idea of using a multi-input LSTM combined with technical indicators came from my own experience with multimodal learning in NLP, but talking it through helped me understand why this specific approach makes sense for financial data.

### Next Steps
My plan moving forward is to start by acquiring all the necessary data through APIs, then do exploratory analysis to understand the distributions, correlations, and stationarity of the features. I'll build a simple baseline model first with just an LSTM on raw price data to establish what performance looks like before adding complexity. Then I'll systematically add technical indicators and context features, experiment with different layer depths and hidden dimensions, and maybe try adding attention mechanisms if the basic architecture works well. The final evaluation will be rigorous testing on the held-out test set using multiple metrics to really understand what the model learned and whether it's actually useful or just fitting noise.